# 统计学常用概念

## 正则化 - Regularization

**目的**：

- 减少模型的过拟合（Over Fitting）问题，提高模型的泛化能力（Generalization）。
- 正则化通过引入额外的约束或惩罚项，使模型更加简单和稳定。

**方法**：

- **L1 正则化（Lasso）**：在损失函数中加入参数的绝对值和作为惩罚项，形式为 \( \lambda \sum |w_i| \)。L1 正则化会使一些参数变为零，从而实现特征选择。
- **L2 正则化（Ridge）**：在损失函数中加入参数的平方和作为惩罚项，形式为 \( \lambda \sum w_i^2 \)。L2 正则化会使参数值减小，但不会使其变为零。
- **Elastic Net 正则化**：结合了 L1 和 L2 正则化的优点。

**应用场景**：

- 正则化常用于回归模型（如线性回归、逻辑回归）和神经网络中，以防止模型过度拟合训练数据。

**例子**：
在 Python 中使用 L2 正则化的线性回归：

```python
from sklearn.linear_model import Ridge

model = Ridge(alpha=1.0)
model.fit(X_train, y_train)
```

## 标准化 - Normalization

**目的**：

- 将数据缩放到相同的尺度，以确保所有特征在相同的范围内，从而提高模型的训练效果和收敛速度。
- 标准化通过调整数据的分布，使其均值为0，标准差为1。

**方法**：

- **Z-score 标准化**：将每个特征的值减去均值，再除以标准差，公式为 \( z = \frac{x - \mu}{\sigma} \)。
- **Min-Max 标准化**：将数据缩放到一个指定的最小值和最大值范围内，通常是 [0, 1]，公式为 \( x' = \frac{x - x_{\text{min}}}{x_{\text{max}} - x_{\text{min}}} \)。

**应用场景**：

- 标准化常用于需要梯度下降法优化的机器学习算法（如支持向量机、神经网络）以及基于距离的算法（如 k-最近邻算法）。

**例子**：
在 Python 中使用 Z-score 标准化：

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
```

## 标准正态分布 - Standard Normal Distribution

标准正态分布是指均值为0、标准差为1的正态分布。标准正态分布的概率密度函数公式为：

\[ f(x) = \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}} \]

其中，\( x \) 是随机变量，\( \pi \) 是圆周率，\( e \) 是自然对数的底。

标准正态分布有以下几个关键特征：

- **均值（Mean）**：0
- **方差（Variance）**：1
- **标准差（Standard Deviation）**：1
- **对称性（Symmetry）**：关于均值对称，即 \( x \) 的分布关于 0 对称。

在标准正态分布下，数据的标准化可以通过减去均值并除以标准差来实现，这个过程称为 **Z-score 标准化**（Z-score normalization）。公式如下：

\[ Z = \frac{X - \mu}{\sigma} \]

其中，\( Z \) 是标准化后的值，\( X \) 是原始值，\( \mu \) 是均值，\( \sigma \) 是标准差。

这种标准化方法将不同尺度的数据转换到一个共同的尺度上，使得它们具有相同的均值和标准差，从而便于比较和分析。

将任意正态分布转换为标准正态分布的过程称为 **Z-score 标准化**（Z-score normalization）或标准化。这个过程将数据转换为均值为0、标准差为1的标准正态分布。具体步骤如下：

**公式**

对于给定的正态分布 \( X \)（均值为 \( \mu \)，标准差为 \( \sigma \)），可以使用以下公式将其转换为标准正态分布 \( Z \)：

\[ Z = \frac{X - \mu}{\sigma} \]

**步骤**

1. **计算均值** (\( \mu \))：计算原始数据集的均值。
2. **计算标准差** (\( \sigma \))：计算原始数据集的标准差。
3. **应用公式**：对于数据集中的每一个值 \( X \)，使用公式 \( Z = \frac{X - \mu}{\sigma} \) 计算标准化后的值。

## 期望值 和 均值 - Expectation and Mean

期望值（Expectation）和均值（Mean）在统计学和概率论中是两个密切相关但略有不同的概念。以下是它们的区别和联系：

**期望值（Expectation）**

期望值是随机变量的一种理论平均值，是根据概率分布计算得到的。

- **定义**：
  - 对于离散型随机变量 \( X \) 及其概率分布 \( P(X = x_i) = p_i \)，期望值 \( E(X) \) 定义为：
    \[ E(X) = \sum_{i} x_i \cdot p_i \]
  - 对于连续型随机变量 \( X \) 及其概率密度函数 \( f(x) \)，期望值 \( E(X) \) 定义为：
    \[ E(X) = \int_{-\infty}^{\infty} x \cdot f(x) \, dx \]

- **本质**：期望值是一个理论值，它表示随机变量在长时间内或大量重复实验中的平均结果。它是一个概率分布的特征值。

**均值（Mean）**

均值是对一组实际观测数据的简单平均值。

- **定义**：对于一组观测数据 \( x_1, x_2, \ldots, x_n \)，均值（通常称为算术平均数）定义为：
  \[ \text{Mean} = \bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i \]
- **本质**：均值是对样本数据的集中趋势的度量，是样本数据的实际计算结果。

**区别和联系**

1. **本质区别**：
   - 期望值是理论上的平均值，是对随机变量及其分布的数学期望。
   - 均值是对一组实际观测数据的平均值，是对数据样本的统计量。
2. **计算方式**：
   - 期望值需要知道随机变量的概率分布或概率密度函数。
   - 均值直接通过对观测数据进行算术平均计算得到。
3. **使用场景**：
   - 期望值用于描述随机变量的理论特性，在概率论和统计学理论中使用广泛。
   - 均值用于描述样本数据的中心趋势，在实际数据分析和统计描述中使用广泛。
4. **关系**：
   - 当样本量足够大时，样本的均值会趋近于随机变量的期望值。这是大数法则的结果，即大量观测数据的均值会接近其理论期望值。

**示例**

假设我们有一个随机变量表示掷一枚公平硬币，正面记为1，反面记为0。

- **期望值**：对于随机变量 \( X \)，它的期望值是
  \[ E(X) = 0 \cdot P(X=0) + 1 \cdot P(X=1) = 0 \cdot 0.5 + 1 \cdot 0.5 = 0.5 \]
- **均值**：如果我们实际掷硬币10次，得到的结果是 \( \{1, 0, 1, 1, 0, 0, 1, 1, 0, 1\} \)，则均值为
  \[ \text{Mean} = \frac{1+0+1+1+0+0+1+1+0+1}{10} = 0.6 \]

这里，期望值是理论上的平均结果，而均值是实际观测数据的平均值。随着实验次数增加，均值会逐渐接近期望值。

通过理解期望值和均值的区别和联系，可以更好地应用它们来分析数据和描述随机现象。
